ü¶ç What is Apache Kafka?
Apache Kafka is a distributed event streaming platform designed for high-throughput, low-latency, fault-tolerant message processing. It‚Äôs widely used for real-time data pipelines, stream processing, and event-driven architectures.

Think of Kafka as a durable, high-performance event log shared across systems.

üß± Kafka Core Concepts
| Component              | Description                                       |
| ---------------------- | ------------------------------------------------- |
| **Producer**           | Sends (publishes) messages to a topic             |
| **Consumer**           | Reads (subscribes) messages from a topic          |
| **Topic**              | Logical name to which messages are sent           |
| **Partition**          | Sub-division of a topic for scalability           |
| **Broker**             | Kafka server that stores messages                 |
| **Cluster**            | Group of Kafka brokers                            |
| **Zookeeper** (Legacy) | Coordinates Kafka nodes (being replaced by KRaft) |
| **Consumer Group**     | Group of consumers that divide the load           |
| **Offset**             | Position of a message in a partition              |


üîÅ Kafka Message Flow
scss
Copy
Edit
Producer ‚Üí Topic (partitioned) ‚Üí Broker ‚Üí Consumer Group ‚Üí Consumers
üì¶ Example of Kafka Topic Structure
sql
Copy
Edit
Topic: order-events

Partition 0: [offset 0] [offset 1] ...
Partition 1: [offset 0] [offset 1] ...
Each consumer group reads one offset per partition, meaning multiple apps can process the same data independently.

üåÄ Kafka Features
| Feature                 | Kafka Supports       |
| ----------------------- | -------------------- |
| Durability              | ‚úÖ                    |
| Message Replay          | ‚úÖ                    |
| Partitioned Parallelism | ‚úÖ                    |
| High Throughput         | ‚úÖ                    |
| Pub/Sub Pattern         | ‚úÖ                    |
| Message Ordering        | ‚úÖ (within partition) |
| Exactly Once Semantics  | ‚úÖ (complex setup)    |


üóÉÔ∏è Kafka vs RabbitMQ (Quick Summary)
| Feature         | Kafka                       | RabbitMQ                              |
| --------------- | --------------------------- | ------------------------------------- |
| Storage         | Log-based (durable)         | Queue-based (ephemeral)               |
| Replay Events   | ‚úÖ                           | ‚ùå (unless manually implemented)       |
| High Throughput | ‚úÖ (millions/sec)            | ‚ùå (lower by design)                   |
| Ordering        | Per-partition               | Per-queue                             |
| Use Case        | Stream processing, logging  | Background jobs, RPC, async workflows |
| Scalability     | Horizontal (via partitions) | Limited                               |


üìä Kafka Use Cases
Log Aggregation (e.g., from microservices)

Real-Time Analytics (e.g., user clickstream)

Event Sourcing

Microservice Communication (Event-driven architecture)

Metrics Collection

ETL Pipelines

üß∞ Kafka Architecture Overview
sql
Copy
Edit
+------------+      +-----------+     +-------------+
| Producer 1 | ---> |  Kafka    | --> | Consumer 1  |
| Producer 2 | ---> |  Cluster  | --> | Consumer 2  |
+------------+      +-----------+     +-------------+
                      ‚Üë     ‚Üë
                   Topic, Partition
‚úÖ Kafka Programming (Java + Spring Boot)
1. Maven Dependency
xml
Copy
Edit
<dependency>
  <groupId>org.springframework.kafka</groupId>
  <artifactId>spring-kafka</artifactId>
</dependency>
2. Kafka Producer Example
java
Copy
Edit
@Autowired
private KafkaTemplate<String, String> kafkaTemplate;

public void sendEvent() {
    kafkaTemplate.send("order-topic", "Order #123 created");
}
3. Kafka Consumer Example
java
Copy
Edit
@KafkaListener(topics = "order-topic", groupId = "order-group")
public void listen(String message) {
    System.out.println("Received: " + message);
}
4. Kafka Config (application.yml)
yaml
Copy
Edit
spring:
  kafka:
    bootstrap-servers: localhost:9092
    consumer:
      group-id: order-group
      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
üîÑ Kafka Partitioning
Topics are split into partitions.

Messages within a partition are ordered.

Consumers in the same group share partitions.

text
Copy
Edit
Topic: payments-events
Partitions: 3
Consumers: C1, C2, C3 (in same group)
‚Üí Parallel processing of events
üõ°Ô∏è Advanced Kafka Concepts
| Feature                | Description                        |
| ---------------------- | ---------------------------------- |
| **Kafka Streams**      | Java library for stream processing |
| **KSQL / ksqlDB**      | SQL-like querying on Kafka data    |
| **Kafka Connect**      | Data import/export from Kafka      |
| **Schema Registry**    | Manages schemas (Avro, JSON, etc.) |
| **Compaction**         | Keep only the latest value per key |
| **Retention Policies** | Delete messages after time or size |


üìú Kafka with Spring Cloud Stream (Optional Abstraction)
If you want to decouple from Kafka directly:

java
Copy
Edit
@EnableBinding(Sink.class)
public class MyListener {
    @StreamListener(Sink.INPUT)
    public void consume(String message) {
        System.out.println("Received: " + message);
    }
}
üí° Best Practices
Choose the right partitioning key to ensure load balance.

Monitor consumer lag to detect slow consumers.

Use dead letter topics for failed messages.

Enable retry and error handling in consumers.

Use idempotent producers or message keys for duplicates.